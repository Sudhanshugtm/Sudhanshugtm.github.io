# Voice notes â€” raw thoughts, unfiltered
# Add new entries at the top (newest first)

- date: "2026-02-23"
  file: "thought-001.mp3"
  caption: "Why we're drawn to LLMs"
  duration: "1:42"
  transcript: "Why don't we really like using LLMs? I was discussing this with one of my colleagues, and we were sharing our points of view, and then post-conversation, I was reflecting back on our conversation, and I had this analogy in my mind. Let's imagine you're talking to an expert about, let's say, the design field, and in the mid-conversation, you basically talk to them about something else. It's going to take time for the person to basically switch context, given they know about the other field as well. But this is where I guess LLMs are very quick to change the context. But I'm not sure when they change the context, how reliable the information they provide about the different field, which maybe I as a human being don't know much about. In conclusion, I feel like these systems thrive because they can produce volume of information at speed which our brain wasn't really there. I feel like this is one of the impressive part about these systems."
